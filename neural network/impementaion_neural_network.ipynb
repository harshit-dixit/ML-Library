{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is a NEURAL NETWORK CLASSIFIER module.\\n   \\nTo use this module - \\n   >> import neuralNetwork as nn\\n\\n1. Create an object\\n   >> stat = knn.det( matrix of (m examples X n features ),matrix of (m output examples X 1, number of classes) )\\n   Output labels can be any number or strings.\\n \\n2. Provide essential data\\n   >> stat.parameter( 'list' of number of units in required number of hidden layers , number of unit in output layer )\\n\\n3. Plot graph to ensure the optimization of cost function to guess alpha and number of iterations.\\n   >> stat.plotJvsno(alpha, number of iterations,regularisation parameter(default=0), batch size (default=batch GradDescent))\\n\\n3. Obtain Theta - a list containing appropriate theta1, theta2, and so on\\n   >> Theta = stat.gettheta(alpha, number of iterations,regularisation parameter(default=0), batch size (default=batch GradDescent))\\n\\n4. To obtain output -\\n   >> y_predict = stat.predict( feature test matrix )\\n\\n5. Accuracy  can be determined by -\\n   >> accuracy = stat.accuracy(X_test,y_test)\\n\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a NEURAL NETWORK CLASSIFIER module.\n",
    "   \n",
    "To use this module - \n",
    "   >> import neuralNetwork as nn\n",
    "\n",
    "1. Create an object\n",
    "   >> stat = knn.det( matrix of (m examples X n features ),matrix of (m output examples X 1, number of classes) )\n",
    "   Output labels can be any number or strings.\n",
    " \n",
    "2. Provide essential data\n",
    "   >> stat.parameter( 'list' of number of units in required number of hidden layers , number of unit in output layer )\n",
    "\n",
    "3. Plot graph to ensure the optimization of cost function to guess alpha and number of iterations.\n",
    "   >> stat.plotJvsno(alpha, number of iterations,regularisation parameter(default=0), batch size (default=batch GradDescent))\n",
    "\n",
    "3. Obtain Theta - a list containing appropriate theta1, theta2, and so on\n",
    "   >> Theta = stat.gettheta(alpha, number of iterations,regularisation parameter(default=0), batch size (default=batch GradDescent))\n",
    "\n",
    "4. To obtain output -\n",
    "   >> y_predict = stat.predict( feature test matrix )\n",
    "\n",
    "5. Accuracy  can be determined by -\n",
    "   >> accuracy = stat.accuracy(X_test,y_test)\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import neuralNetwork as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(a, b):\n",
    "  assert len(a) == len(b)\n",
    "  p = np.random.permutation(len(a))\n",
    "  return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "data = pd.read_csv('data/Moon.txt',header=None,sep=',')\n",
    "data = np.array(data.values)\n",
    "X = data[:,0:2]\n",
    "y = data[:,2:3]\n",
    "X,y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating in train and test set\n",
    "\n",
    "m = np.shape(X)[0]\n",
    "X_train = X[0:int(0.7*m),:]\n",
    "y_train = y[0:int(0.7*m)]\n",
    "X_test = X[int(0.7*m):,:]\n",
    "y_test = y[int(0.7*m):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object. Parameter takes - (list of number of units in hidden layer,number of unit in output layer)\n",
    "\n",
    "stat = nn.optimize(X_train,y_train)\n",
    "stat.parameter([25,25],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,700) and (3,700) not aligned: 700 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\impementaion_neural_network.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91983/Desktop/ml_library/neural%20network/impementaion_neural_network.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# plot graph to ensure minimization of cost function to guess value of alpha and other parameters\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/91983/Desktop/ml_library/neural%20network/impementaion_neural_network.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m stat\u001b[39m.\u001b[39;49mplotJvsno(\u001b[39m0.4\u001b[39;49m,\u001b[39m300\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\neuralNetwork.py:245\u001b[0m, in \u001b[0;36moptimize.plotJvsno\u001b[1;34m(self, alpha, iterations, lambda_, batsize, v)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplotJvsno\u001b[39m(\u001b[39mself\u001b[39m,alpha,iterations\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,lambda_\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,batsize \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,v\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 245\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgettheta(alpha,iterations,lambda_,batsize,v)\n\u001b[0;32m    246\u001b[0m   plt\u001b[39m.\u001b[39mplot(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,iterations),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpltdata,\u001b[39m'\u001b[39m\u001b[39mg-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    247\u001b[0m   plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mIterations\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\neuralNetwork.py:90\u001b[0m, in \u001b[0;36moptimize.gettheta\u001b[1;34m(self, alpha, iterations, lambda_, batsize, v)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mBatch size is invalid. Running Batch Gradient Descent\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatsize \u001b[39m=\u001b[39m m\n\u001b[1;32m---> 90\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradDescent()\n\u001b[0;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTheta\n",
      "File \u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\neuralNetwork.py:183\u001b[0m, in \u001b[0;36moptimize.gradDescent\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m   X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX[ j : j \u001b[39m+\u001b[39m batsize ,:]\n\u001b[0;32m    182\u001b[0m   y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[ j : j \u001b[39m+\u001b[39m batsize ,:]\n\u001b[1;32m--> 183\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrad(Theta,X,y)\n\u001b[0;32m    184\u001b[0m   Theta \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m( \u001b[39mlambda\u001b[39;00m x,y: x \u001b[39m-\u001b[39m alpha\u001b[39m*\u001b[39my , Theta , \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGrad )\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: pltdata\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcostfunc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my,Theta))\n",
      "File \u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\neuralNetwork.py:157\u001b[0m, in \u001b[0;36moptimize.grad\u001b[1;34m(self, Theta, X, y)\u001b[0m\n\u001b[0;32m    155\u001b[0m   temp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack([np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m],\u001b[39m1\u001b[39m)),temp[:,\u001b[39m1\u001b[39m:]])\n\u001b[0;32m    156\u001b[0m   regular \u001b[39m=\u001b[39m ((\u001b[39m1.0\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_)\u001b[39m/\u001b[39mm)\u001b[39m*\u001b[39mtemp\n\u001b[1;32m--> 157\u001b[0m   k \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39mm)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39;49mdot(Del[i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m],A[i]) \u001b[39m+\u001b[39m regular\n\u001b[0;32m    158\u001b[0m   Grad\u001b[39m.\u001b[39mappend(k)\n\u001b[0;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mGrad \u001b[39m=\u001b[39m Grad\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,700) and (3,700) not aligned: 700 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "# plot graph to ensure minimization of cost function to guess value of alpha and other parameters\n",
    "\n",
    "stat.plotJvsno(0.4,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gettheta will return Theta, array  with theta1 as Theta[1], and so on so on..\n",
    "# gettheta takes - (alpha, number of iterations,regularisation parameter(default=0), batch size (default=batch GradDescent))\n",
    "\n",
    "Theta = stat.gettheta(0.04,300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'optimize' object has no attribute 'Theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\impementaion_neural_network.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91983/Desktop/ml_library/neural%20network/impementaion_neural_network.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# predicting\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/91983/Desktop/ml_library/neural%20network/impementaion_neural_network.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_predict \u001b[39m=\u001b[39m stat\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\91983\\Desktop\\ml_library\\neural network\\neuralNetwork.py:196\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    194\u001b[0m x = x - self.mean\n\u001b[0;32m    195\u001b[0m x = x.T\n\u001b[1;32m--> 196\u001b[0m [A,Z] = self.forprop(x,self.Theta)\n\u001b[0;32m    197\u001b[0m   \n\u001b[0;32m    198\u001b[0m   \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'optimize' object has no attribute 'Theta'"
     ]
    }
   ],
   "source": [
    "# predicting\n",
    "\n",
    "y_predict = stat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 %\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "\n",
    "print (stat.accuracy(X_test,y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 %\n"
     ]
    }
   ],
   "source": [
    "# comparing accuracy with scikit\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(25, 25), random_state=1)\n",
    "clf.fit(X_train,y_train.ravel())\n",
    "y_predict = clf.predict(X_test)\n",
    "y_predict = np.reshape(y_predict,(np.shape(y_predict)[0],1))\n",
    "y = y_predict\n",
    "k = (y==y_test)\n",
    "k = k.astype(int)\n",
    "\n",
    "print (np.sum(k)*100/np.shape(y_test)[0],'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a837f42e33ba97e3e78d95dc589f0b31516f08c4adf657443a0c0ef738510f56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
